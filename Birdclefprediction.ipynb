{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T13:26:06.286526Z",
     "iopub.status.busy": "2025-04-06T13:26:06.286106Z",
     "iopub.status.idle": "2025-04-06T13:26:09.282601Z",
     "shell.execute_reply": "2025-04-06T13:26:09.281344Z",
     "shell.execute_reply.started": "2025-04-06T13:26:06.286486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import random \n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    seed=42\n",
    "    train_csv='/kaggle/input/birdclef-2025/train.csv'\n",
    "    taxonomy_csv='/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "    samp_sumbission_csv='/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "    test_soundscapes_csv = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "    trainaudio_csv = '/kaggle/input/birdclef-2025/train_audio'\n",
    "    optimizer = 'AdamW'\n",
    "    lr = 5e-4 \n",
    "    weight_decay = 1e-5\n",
    "    model_name='efficientnet_b0'\n",
    "    pretrained = True\n",
    "    in_channels = 1\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    FS = 32000\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    epochs=20\n",
    "    batch_size=32\n",
    "    criterion = 'BCEWithLogitsLoss'\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    min_lr = 1e-6\n",
    "    T_max = epochs\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256) \n",
    "cfg=CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_sig=np.nanmean(audio_data)\n",
    "        audio_data=np.nantonum(audio_data,nan=mean_sig)\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "    y=audio_data,\n",
    "    sr=32000,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=128,\n",
    "    fmin=50,\n",
    "    fmax=14000,\n",
    "    power=2.0,\n",
    ")\n",
    "    audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n",
    "    target_samples = int(cfg.TARGET_DURATION * cfg.FS)\n",
    "    if len(audio_data) < target_samples:\n",
    "            n_copy = math.ceil(target_samples / len(audio_data))\n",
    "            if n_copy > 1:\n",
    "                audio_data = np.concatenate([audio_data] * n_copy)\n",
    "    len_start=max(0, int(len(audio_data) / 2 - target_samples / 2))\n",
    "    len_end = min(len(audio_data), start_idx + target_samples)\n",
    "    center_audio = audio_data[len_start:len_end]\n",
    "        if len(center_audio) < target_samples:\n",
    "            center_audio = np.pad(center_audio, (0, target_samples - len(center_audio)), mode='constant')\n",
    "    mel_spec = audio2melspec(center_audio, cfg)\n",
    "    if mel_spec.shape != cfg.TARGET_SHAPE:\n",
    "        mel_spec = cv2.resize(mel_spec, cfg.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "    return mel_spec.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "def spectogram(cfg,code)\n",
    "    start_time = time.time()\n",
    "\n",
    "    all_bird_data = {}\n",
    "    errors = []\n",
    "     try:\n",
    "            samplename = row['samplename']\n",
    "            filepath = row['filepath']\n",
    "            mel_spec = process_audio_file(filepath, cfg)\n",
    "            if mel_spec is not None:\n",
    "                all_bird_data[samplename] = mel_spec\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {row.filepath}: {e}\")\n",
    "                errors.append((row.filepath, str(e)))\n",
    "            end_time = time.time()\n",
    "    return all_bird_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Birdcleffromnpy()\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectograms=spectograms\n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.df['filename'].apply(\n",
    "                lambda f: os.path.join(self.cfg.train_datadir, f)\n",
    "            )\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df['filename'].apply(\n",
    "                lambda x: x.split('/')[0] + '-' + Path(x).stem\n",
    "            )\n",
    "        if self.spectrograms:\n",
    "        found_samples = self.df['samplename'].isin(self.spectrograms).sum()\n",
    "            print(f\"Found {found_samples} matching spectrograms for {mode} dataset out of {len(self.df)} samples\")\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        samplename = row['samplename']\n",
    "        spec = None\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "        if spec is None:\n",
    "            spec=np.zeroes(self.cfg.TARGET_SHAPE,dtype=np.float32)\n",
    "            if self.mode==\"train\":\n",
    "                print(f\"Warning :Spectogram for{samplename} not found coludnt be genrated\")\n",
    "                spec = torch.tensor(spec,dtype=torch.float32).unsqueeze(0)\n",
    "            if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "                spec = self.apply_spec_augmentations(spec)\n",
    "            target = self.encode_label(row['primary_label'])\n",
    "            if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:       \n",
    "            secondary_labels = row.get('secondary_labels', [])\n",
    "            if isinstance(secondary_labels, str):\n",
    "                try:\n",
    "                    secondary_labels = eval(secondary_labels)\n",
    "                except:\n",
    "                    secondary_labels = []\n",
    "            if isinstance(secondary_labels, list) and secondary_labels != [''] and secondary_labels is not None:\n",
    "                for label in secondary_labels:\n",
    "                    idx = self.label_to_idx.get(label)\n",
    "                    if idx is not None:\n",
    "                        target[idx] = 1.0\n",
    "            return {\n",
    "                'melspec': spec, \n",
    "                'target': torch.tensor(target, dtype=torch.float32),\n",
    "                'filename': row['filename']\n",
    "            }\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        #horizontal\n",
    "        if random.random() < 0.5:\n",
    "            num_masks = random.randint(1, 3)\n",
    "            for _ in range(num_masks):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "                #vertical\n",
    "        if random.random() < 0.5:\n",
    "            num_masks = random.randint(1, 3)\n",
    "            for _ in range(num_masks):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init()\n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        self.cfg=cfg\n",
    "        cfg.num_classes = len(taxonomy_df)\n",
    "        self.model = timm.create_model(cfg.model_name, pretrained=cfg.pretrained, in_channels=cfg.in_channels,drop_rate=0.2,drop_path_rate=0.2)\n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out=self.backbone.classifier.in_features\n",
    "            self.backbone.classifier.in_features\n",
    "            self.backbone.classifier=nn.Identitiy()\n",
    "            elif 'resnet in' in cfg.model_name:\n",
    "            backbone_out=self.backbone.fc.in_features\n",
    "        else:\n",
    "            backbone_out=self.backbone.get_classifier().in_features\n",
    "            self.backbone.resnet_classifier(0,'')\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "    def forward(self, x, targets=None):\n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "              \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                        logits, targets_a, targets_b, lam)\n",
    "                return logits, loss\n",
    "                \n",
    "            return logits\n",
    "        \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 6886569,
     "sourceId": 11053663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
